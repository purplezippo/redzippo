---
title: MCMC方法解析
author: 雨禾
date: '2019-03-12'
slug: MCMC方法解析
tags:
  - 贝叶斯
  - 蒙特卡洛
categories: 
  - algorithm
---



<div class="section level1">
<h1>1.简介</h1>
<div class="section level2">
<h2>概要</h2>
<p>MCMC,也称为马尔科夫链蒙特卡洛(Markov Chain Monte Carlo)方法，是用于从复杂分布中获取随机样本的统计学算法。正是MCMC方法的提出使得许多贝叶斯统计问题的求解成为可能。MCMC方法是一类典型的在编程上容易实现，但原理的解释和理解却相对困难的统计学方法。对于这类方法，如果不能够理解其内部原理便难以在实践过程中进行应用。本次分享会分别就两个MC进行理论介绍，而后对MCMC方法进行阐述，最后通过实例演示应用过程。</p>
</div>
</div>
<div class="section level1">
<h1>2.随机抽样</h1>
<div class="section level2">
<h2>2.1随机性</h2>
<p>随机性的获取实际上并不像我们以为的那样容易，计算指定一个点的概率质量（概率密度）容易，但要随机的算一堆点就要在保证随机性上做很多工作。</p>
<p>一条解决路径是从简单分布中抽取随机样本，然后通过某种变换映射到目标分布中去。比如服从均匀分布的样本可以通过Box-Muller变换映射到正态分布中去，那么为了获取服从正态分布的样本就可以先从均匀分布中抽样再进行变换。那么该如何从均匀分布中进行随机抽样呢？工程上可以通过线性同余发生器来生成服从均匀分布的伪随机数。事实上，许多常用分布都可以通过均匀分布变换而来。</p>
<!-- <div class='centered'> -->
<!-- ![](timg2.png) -->
<!-- </div> -->
<p>
<img src="/post/2019-03-12-mcmc方法解析_files/figure-html/img1.png" width="672" />
</p>
<blockquote>
<p>如何手工获取随机数？</p>
</blockquote>
<p>当然通常为了获取服从某个分布的样本都是直接使用现成的程序库，并不用关心程序背后的原理。但问题是在实践中并不是所有分布都能够在标准的程序库中找到相应的方法，甚至有些分布的形式都无显式的用公式进行表示。这时候MCMC就派上用场了。</p>
</div>
</div>
<div class="section level1">
<h1>3.蒙特卡洛模拟</h1>
<div id="-1" class="section level2">
<h2>3.1 简介</h2>
<p>蒙特卡洛模拟是一类通过随机抽样过程来求取最优解的方法的总称，如果建立蒙特卡洛模型的过程没有出错，那么抽样次数越多，得到的答案越精确。 蒙特卡洛模拟的实现，可以归纳为如下三个步骤：</p>
<ul>
<li>a 将欲求解问题转化为概率过程。</li>
<li>b 从已知分布中抽样</li>
<li>c 通过样本计算各类统计量，此类统计量就是欲求问题的解。</li>
</ul>
<p><img src="/post/2019-03-12-mcmc方法解析_files/figure-html/unnamed-chunk-1-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div class="section level2">
<h2>3.2 示例</h2>
<div class="section level3">
<h3>3.2.1问题</h3>
<p>将新生随机分配，构成一个60人的班级，求解任何两个人的生日都不在同一天的概率。</p>
</div>
<div class="section level3">
<h3>3.2.2求解</h3>
<p>构建蒙特卡洛过程：</p>
<ul>
<li>a 由于学生是随机分配到一个班级的，所以每个人的出生日期是独立的，并且是从1~365之内等概率取值的。构造统计量<span class="math inline">\(B\sim P365(p1,p2,\dots,p365)，p1=p2=,\dots,p365=\frac{1}{365}\)</span>，则从<span class="math inline">\(P365\)</span>中抽样的行为可视为对学生分配到班级的模拟。那么抽样60次组成的集合就是对一个班级的模拟。因此定义一次抽样就是<span class="math inline">\(s_i=(b_{i1},\dots,b_{i60})\)</span></li>
<li>b 重复第一步N次，N取一个足够大的数，这里暂且取N为10000。</li>
<li>c 令<span class="math inline">\(sign(s_i)=1\)</span>表示第i个样本中任意两个数都不相等，<span class="math inline">\(sign(s_i)=0\)</span>表示只要有两个数相等。则有：<span class="math inline">\(P(没有人的生日在同一天)\approx\frac{1}{N}\sum _{i=1}^Nsum(sign(s_i))\)</span></li>
</ul>
<pre class="r"><code>prob.one &lt;- function(n,N){
    samples &lt;- trunc(runif(n*N,1,366))
    samples[samples == 366] &lt;- 365
    birdays &lt;- matrix(samples,ncol = n)
    onedayrate &lt;- apply(birdays,1,function(x){return(n - length(unique(x)))})
    nonday &lt;- sum(onedayrate == 0)
    par(mfrow = c(1,2))
    hist(onedayrate, breaks = 10, xlab = &#39;&#39;, main = &quot;生日在同一天的人数&quot;,col = &quot;pink&quot;)
    pie(table(as.integer(onedayrate != 0)), main = paste(&quot;没有人同一天的概率:&quot;, nonday/N),
        labels = c(&#39;无重叠&#39;, &#39;有重叠&#39;),col = c(&#39;orangered&#39;, &#39;cornflowerblue&#39;), border = NA)
}
prob.one(60, 10000)</code></pre>
<p><img src="/post/2019-03-12-mcmc方法解析_files/figure-html/unnamed-chunk-2-1.png" width="864" /></p>
</div>
</div>
</div>
<div class="section level1">
<h1>4.马尔科夫链</h1>
<div class="section level2">
<h2>4.1定义</h2>
<div class="section level3">
<h3>4.1.1 马尔科夫性</h3>
<p>对于随机过程，由时刻<span class="math inline">\(t_0\)</span>系统或过程所处状态，可以决定系统或过程在时刻<span class="math inline">\(t&gt;t_0\)</span>所处状态，而无需借助<span class="math inline">\(t_0\)</span>以前系统或过程所处状态。即，在已知“现在”的条件下对，其“将来”不依赖于过去。 对于随机过程<span class="math inline">\(\{X(t),t\in T\}\)</span>,有： <span class="math display">\[
P\{X(t_n)\le x_n|,X(t_1)=x_1,X(t_2)=x_2,\dots,X(t_{(n-1)})=x_{(n-1)}\} \\
=P\{X(t_n)\le x_n|X(t_{(n-1)})=x_{(n-1)}\},x_n\in \mathbb{R}
\]</span></p>
<ul>
<li>a 具有马尔科夫性的随机过程为<strong>马尔科夫过程</strong>。</li>
<li>b 时间和状态都是离散的马尔科夫过程为<strong>马尔科夫链</strong>也作马氏链。</li>
</ul>
</div>
<div class="section level3">
<h3>4.1.2 转移概率矩阵</h3>
<p>定义状态转移概率如下： <span class="math display">\[
P_{ij}(m, m + n)=P\{X_{m+n}=a_j|X_{m}=a_i\}\\
\sum_{j=i}^{+\infty}P_{ij}(m,m+n)=1,i=1,2,\dots
\]</span> 由状态转移概率组成的矩阵称为<strong>转移概率</strong>矩阵<span class="math inline">\(P(m,m+n)\)</span>. 当<span class="math inline">\(P_{ij}(m, m + n)\)</span>只与<span class="math inline">\(i,j,n\)</span>有关时，又可记为<span class="math inline">\(P_{ij}(n)\)</span>,此时称此转移概率具有<strong>平稳性</strong>，并且称链具有<strong>齐次性</strong>。<span class="math inline">\(P(n)\)</span>则称为<span class="math inline">\(n\)</span>步转移概率矩阵。</p>
</div>
</div>
<div class="section level2">
<h2>4.2性质</h2>
<div id="c-k" class="section level3">
<h3>4.2.1 C-K方程</h3>
<p><span class="math display">\[
P(u + v) = P(u)P(v)
\]</span> 由此推出： <span class="math display">\[
P(n) = P(1)P(n-1)=P(1)P(1)P(n-2)=\dots=P(1)^n
\]</span> 因此对于齐次马氏链，任意步长的转移概率矩阵由1阶转移概率矩阵唯一确定。</p>
</div>
<div class="section level3">
<h3>4.2.2 遍历性</h3>
<p>若对于<span class="math inline">\(P_{ij}(n)\)</span>有： <span class="math display">\[
\lim_{n\to+\infty}P_{ij}(n)=\pi_j, 不依赖于i
\]</span> 则称链有便利性，又若<span class="math inline">\(\sum_j\pi_j=1\)</span>,则称<span class="math inline">\(\pi=(\pi_1, \pi_2, \dots)\)</span>为链的极限分布。</p>
<p><strong>定理</strong> 对于其次马氏链，状态空间为<span class="math inline">\(I\in{a_1,\dots,a_N}\)</span>，如果存在正整数<span class="math inline">\(m\)</span>,对任意的<span class="math inline">\(a_i,a_j\)</span>有 <span class="math display">\[
P_{ij}(m)&gt;0, i,j=1,2,\dots,N
\]</span> 则链具有遍历性，且具有极限分布<span class="math inline">\(\pi=(\pi_1, \pi_2, \dots)\)</span>。且满足：<span class="math inline">\(\pi\)</span>是<span class="math inline">\(\pi P = P\)</span>的唯一非负解。 <!-- - $\lim_{n\rightarrow+\infty}P_{ij}^n$存在且与$i$无关。 --></p>
</div>
</div>
<div id="-1" class="section level2">
<h2>4.3示例</h2>
<p>假设媳妇儿的心情大致可分为三种：平静、高兴、愤怒，并且每隔15分钟就会发生一次状态转移，同时下一时刻心情的变化只与上一刻的心情有关。那么根据定义，一段时间内她的心情状态就构成一条马尔科夫链。假定这几种心情状态的一步转移概率矩阵构成如下。 希望知道每天下班回家，见着她时最有可能处于那种心，好提前做好心理准备。</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">平静</th>
<th align="center">高兴</th>
<th align="center">愤怒</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>平静</td>
<td align="center">0.2</td>
<td align="center">0.3</td>
<td align="center">0.5</td>
</tr>
<tr class="even">
<td>高兴</td>
<td align="center">0.1</td>
<td align="center">0.6</td>
<td align="center">0.3</td>
</tr>
<tr class="odd">
<td>愤怒</td>
<td align="center">0.4</td>
<td align="center">0.2</td>
<td align="center">0.4</td>
</tr>
</tbody>
</table>
<p>随意给定初值条件进行概率推演，结果如下。</p>
<pre class="r"><code>pi0 &lt;- matrix(c(0.7, 0.2, 0.1), ncol = 3, byrow = TRUE)# 初始概率 平静 高兴 愤怒
colnames(pi0) &lt;- states_name
PI &lt;- pi0
for (i in 2:10) {PI &lt;- rbind(PI, PI[i - 1,] %*% P_s1)}
print(PI)</code></pre>
<pre><code>##            平静      高兴      愤怒
##  [1,] 0.7000000 0.2000000 0.1000000
##  [2,] 0.2000000 0.3500000 0.4500000
##  [3,] 0.2550000 0.3600000 0.3850000
##  [4,] 0.2410000 0.3695000 0.3895000
##  [5,] 0.2409500 0.3719000 0.3871500
##  [6,] 0.2402400 0.3728550 0.3869050
##  [7,] 0.2400955 0.3731660 0.3867385
##  [8,] 0.2400311 0.3732760 0.3866930
##  [9,] 0.2400110 0.3733135 0.3866755
## [10,] 0.2400038 0.3733265 0.3866698</code></pre>
<p>得知其平稳分布为<span class="math inline">\(\pi=\{\pi_{平静}=0.240, \pi_{高兴}=0.373, \pi_{愤怒}=0.387\}\)</span>，从而发现有0.613的概率不会挨批。于是每天携带一块秒表，进门前按下并读取毫秒数。如果数值 小于0.613放心大胆进门，否则等15分钟再按一次。</p>
</div>
</div>
<div id="mcmc" class="section level1">
<h1>5.MCMC</h1>
<div id="mcmc" class="section level2">
<h2>5.1 MCMC采样</h2>
<div class="section level3">
<h3>5.1.1原理</h3>
<div class="section level4">
<h4>(1)细致平稳条件</h4>
<p><strong>定理</strong> 如果非周期马氏链的转移矩阵<span class="math inline">\(P\)</span>和概率分布<span class="math inline">\(\pi(x)\)</span>满足 <span class="math display">\[
\pi(i) P_{ij} = \pi(j) P_{ji}，对任意的i,j
\]</span> 则<span class="math inline">\(\pi(x)\)</span>为该马氏链的平稳分布。 令<span class="math inline">\(\pi(x)\)</span>为需要抽样的目标分布，则如果能够得到一个转移概率矩阵<span class="math inline">\(P\)</span>使得细致平稳条件成立，那么从一个简单分布中获取随机样本（这里简单分布指容易通过计算机程序进行直接抽样的分布，采用什么样的简单分布，视场景而定），经过<span class="math inline">\(P\)</span>完成若干次转移变换，则最终会到达目标分布从而完成从<span class="math inline">\(\pi(x)\)</span>中进行抽样。因而只要能够确定<span class="math inline">\(P\)</span>，就能够实现抽样。</p>
</div>
<div class="section level4">
<h4>(2)利用细致平稳条件</h4>
<p>既然知道了细致平稳条件这一硬性标杆，即便没有条件，那就创造条件。 假设随机给定一个形式上合规的矩阵<span class="math inline">\(Q\)</span>作为转移矩阵,则细致平稳条件一般无法满足： <span class="math display">\[
p(i)q(i,j)\neq p(j)q(j,i)
\]</span> 此时构造如下两个新变量，分别乘以等式两端。 <span class="math display">\[
\alpha(i,j)=p_jq(j,i), \alpha(j,i)=p_iq(i,j)
\]</span> 由于： <span class="math display">\[
p(i)q(i,j)p(j)q(j,i)=p(j)q(j,i)p(i)q(i,j) 
\]</span> 所以有： <span class="math display">\[
p(i)q(i,j)\alpha{(ij)}=p(j)q(j,i)\alpha{(j,i)} 
\]</span></p>
<p>此时令: <span class="math display">\[
Q^\prime(i,j) = q(i,j)\alpha(i,j), Q^\prime(j,i) = q(j,i)\alpha(j,i)
\]</span> 可知，在引入<span class="math inline">\(Q^\prime\)</span>的条件下，下式成立，也即细致平稳条件满足。满足了细致平稳条件，就可进行抽样了！ <span class="math display">\[
p(i)Q^\prime(i,j)=p(j)Q^\prime(j,i)
\]</span></p>
</div>
<div class="section level4">
<h4>(3)理解</h4>
<p>要理解<span class="math inline">\(Q -&gt; Q^\prime\)</span>的过程是如何实现的，就是要理解<span class="math inline">\(\alpha(i,j)\)</span>在前后两个马氏链的变换上所起到的作用。</p>
<p>假设有一枚不均质的硬币，<span class="math inline">\(P(X=正面)=0.6\)</span>，那么如何模拟一次抛掷的动作呢？如下图所示，问题等价于在[0,1]区间内，在0.6的位置将整个区间分割为[0,0.6],(0.6,1],并向其中随机撒点，任意一次撒点后点落入左侧区间，则表示正面向上，落入右侧区间则表示反面向上。随机撒点的动作，通过<strong>均匀分布</strong>抽样实现。</p>
<p><img src="/post/2019-03-12-mcmc方法解析_files/figure-html/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>在这里<span class="math inline">\(\alpha(i,j)\)</span>，实际上就是扮演了硬币的角色，它的作用就是在保持整个抽样过程随机性的前提下，按概率实现马氏链的更新。</p>
</div>
</div>
<div class="section level3">
<h3>5.1.2算法</h3>
<p>假设Q表示一步状态转移矩阵（对应的在连续的情况下，用D表示概率密度函数）。</p>
<ul>
<li>a 用X表示由MCMC过程产生的状态向量，<span class="math inline">\(Q_0\)</span>表示状态转移矩阵（<span class="math inline">\(D_0\)</span>表示抽样分布）。初始化<span class="math inline">\(X_0=x_0\)</span>，其中<span class="math inline">\(x_0\)</span>是从状态集（分布）中获取的随机样本。</li>
<li>b 对<span class="math inline">\(t = 0, 1, 2, \cdots,n\)</span>重复如下步骤进行采样：
<div class="columns-2">

</div></li>
<li>b-1 第<span class="math inline">\(t\)</span>时刻有<span class="math inline">\(X_t=x_t\)</span>, 采样<span class="math inline">\(y~q(x|x_t)\)</span>(此时状态转移矩阵为<span class="math inline">\(Q_t=q(x|x_t)\)</span>)。</li>
<li>b-2 从<span class="math inline">\(U(0,1)\)</span>中抽取一个样本点<span class="math inline">\(u\)</span></li>
<li>b-3 如果<span class="math inline">\(u&lt;\alpha(x_t, y)=p(y)*q(x_t|y)\)</span>则接受转移<span class="math inline">\(X_{t+1}=y\)</span></li>
<li>b-4 否则拒绝转移，<span class="math inline">\(X_{t+1}=x_t\)</span>, <span class="math inline">\(Q_{t+1} = Q_t\)</span></li>
</ul>
</div>
</div>
<div id="m-h" class="section level2">
<h2>5.2 M-H方法</h2>
<div id="-1" class="section level3">
<h3>5.2.1原理</h3>
<p>由于<span class="math inline">\(\alpha(i,j)=p_{j}q(j,i) &lt; 1\)</span>，通常是一个比较小的数字，因此在一次采样中很容易拒绝跳转。从而导致采样的时间成本、计算成本很高。M-H(Metropolis-Hastings)采样，通过放大跳转率<span class="math inline">\(\alpha(i,j)\)</span>提高了跳转概率，缩短了采样过程。 对下式两边同时除以<span class="math inline">\(p(i)q(i,j)\)</span> <span class="math display">\[
p(i)q(i,j)p(j)q(j,i)=p(j)q(j,i)p(i)q(i,j) \\ 
p(i)q(i,j)\frac{p(j)q(j,i)}{p(i)q(i,j)}=p(j)q(j,i) 
\]</span> 此时有 <span class="math display">\[
\alpha(i,j)=\frac{p(j)q(j,i)}{p(i)q(i,j)},\alpha(j,i)=1
\]</span></p>
<p>此时，如果<span class="math inline">\(\alpha(i,j) = \frac{p(j)q(j,i)}{p(i)q(i,j)} &lt; 1\)</span>则<span class="math inline">\(\alpha(i,j)\)</span>按照<span class="math inline">\(\alpha(j,i)\)</span>放大到1的比例等比例放大。但如果<span class="math inline">\(\frac{p(j)q(j,i)}{p(i)q(i,j)} &gt; 1\)</span>就不行了，由于概率是不可能大于1的。那么此时就反过来,同除以<span class="math inline">\(p(j)q(j,i)\)</span>.</p>
<p><span class="math display">\[
p(i)q(i,j)p(j)q(j,i)=p(j)q(j,i)p(i)q(i,j) \\ 
p(i)q(i,j)=p(j)q(j,i)\frac{p(i)q(i,j)}{p(j)q(j,i)}
\]</span> 此时有 <span class="math display">\[\alpha(i,j) = 1,\alpha(j,i)=\frac{p(i)q(i,j)}{p(j)q(j,i)}\]</span> 当然为了跳转，需要关心的只有<span class="math inline">\(\alpha(i,j)\)</span>，根据以上推到新的<span class="math inline">\(\alpha(i,j)\)</span>可定义为： <span class="math display">\[
\alpha(i,j)=min(\frac{p(j)q(j,i)}{p(i)q(i,j)},1)
\]</span></p>
<p>对于新的<span class="math inline">\(\alpha\)</span>在取到1的情况下能实现链的满概率跳转，否则以放大<span class="math inline">\(\frac{1}{p(i)q(i,j)}\)</span>倍的概率进行跳转，这就是M-H方法对MCMC方法的改进。</p>
</div>
<div id="-1" class="section level3">
<h3>5.2.2算法</h3>
<p>其它不变，这里只是改变了跳转率的计算方法。</p>
<ul>
<li>a 用X表示由MCMC过程产生的状态向量，<span class="math inline">\(Q_0\)</span>表示状态转移矩阵（<span class="math inline">\(D_0\)</span>表示抽样分布）。初始化<span class="math inline">\(X_0=x_0\)</span>，其中<span class="math inline">\(x_0\)</span>是从状态集（分布）中获取的随机样本。</li>
<li>b 对<span class="math inline">\(t = 0, 1, 2, \cdots,n\)</span>重复如下步骤进行采样：</li>
<li>b-1 第<span class="math inline">\(t\)</span>时刻有<span class="math inline">\(X_t=x_t\)</span>, 采样<span class="math inline">\(y~q(x|x_t)\)</span>(此时状态转移矩阵为<span class="math inline">\(Q_t=q(x|x_t)\)</span>)。</li>
<li>b-2 从<span class="math inline">\(U(0,1)\)</span>中抽取一个样本点<span class="math inline">\(u\)</span></li>
<li><div class="red2">
b-3 如果<span class="math inline">\(u&lt;\alpha(x_t, y)=min(\frac{p(j)q(j,i)}{p(i)q(i,j)},1)\)</span>则接受转移<span class="math inline">\(X_{t+1}=y\)</span>
</div></li>
<li>b-4 否则拒绝转移，<span class="math inline">\(X_{t+1}=x_t\)</span>, <span class="math inline">\(Q_{t+1} = Q_t\)</span></li>
</ul>
</div>
</div>
<div id="gibbs" class="section level2">
<h2>5.3 Gibbs方法</h2>
<div id="-2" class="section level3">
<h3>5.3.1原理</h3>
<div id="m-h" class="section level4">
<h4>(1)M-H方法的局限</h4>
<p>M-H方法，虽然实现了跳转率的放大，但依然不能保证100%的跳转，这就意味着总归还是要浪费不少样本，即使已经到达稳态，也还是经常要抛弃样本。这也极大的限制了M-H算法的应用范围。如果有一种方法，能够保证每次跳转都以100%的概率被接受，那就更完美的解决了这一问题。</p>
</div>
<div class="section level4">
<h4>(2)轮换采样</h4>
<p>对于定义于二维空间中的马氏链，考虑如下等式： <span class="math display">\[
p(x_1, y_1)p(y_2|x_1)=p(x_1)p(y_1|x_1)p(y_2|x_1) \\
p(x_1, y_2)p(y_1|x_1)=p(x_1)p(y_2|x_1)p(y_1|x_1)
\]</span> 两式右边相等，因此有： <span class="math display">\[
p(x_1, y_1)p(y_2|x_1)=p(x_1, y_2)p(y_1|x_1)
\]</span> 这个等式完全满足细致平稳条件，可以实现点<span class="math inline">\((x_1,y_1)\)</span>到点<span class="math inline">\((x_1,y_2)\)</span>以100%的跳转率进行转换。同时可以看到转换后的两点在平行于<span class="math inline">\(y\)</span>轴的同一条直线上。同理可知固定<span class="math inline">\(y\)</span>轴而在<span class="math inline">\(x\)</span>轴的方向上进行采样，也同样满足细致平稳条件。</p>
<p>因此对于二维空间中的马氏链，如下图所示，只要在两个轴的方向上进行采样就不存在拒绝跳转的问题。</p>
<p><img src="/post/2019-03-12-mcmc方法解析_files/figure-html/unnamed-chunk-6-1.png" width="864" /></p>
<p>同理，将这一性质推广到<span class="math inline">\(N\)</span>维空间也是成立的。</p>
</div>
</div>
<div id="-2" class="section level3">
<h3>5.3.2算法</h3>
<p>以二元分布<span class="math inline">\(D(x,y)\)</span>为例</p>
<ul>
<li>a 初始化<span class="math inline">\(X_0=x_0,Y_0=y_0\)</span></li>
<li>b 对<span class="math inline">\(t = 0, 1, 2, \cdots,n\)</span>进行坐标轮换采样</li>
<li>b-1 <span class="math inline">\(y_{t+1}\sim p(y|x_t)\)</span></li>
<li>b-2 <span class="math inline">\(x_{t+1}\sim p(x|y_{t+1})\)</span></li>
</ul>
</div>
</div>
</div>
<div id="-2" class="section level1">
<h1>6.示例</h1>
<div id="m-h" class="section level2">
<h2>6.1 M-H抽样</h2>
<div id="-1" class="section level3">
<h3>问题</h3>
<p>使用M-H方法实现从混合正态分布中抽样。</p>
</div>
<div id="-1" class="section level3">
<h3>求解</h3>
<pre class="r"><code>SomeDist &lt;- function(x){
  if (x &lt; 6) {
    res &lt;- dnorm(x, mean = 6, sd = 2)
  } else {
    res &lt;- dnorm(x, mean = 6, sd = 6)
  }
  return(res)
}
 
n1 = 15000  # burn in
n2 = 25000
samples &lt;- rep(0, n1 + n2)
for (i in 1:(n1 + n2 - 1)) {
  temp &lt;- rnorm(1,mean = samples[i], sd = 4)
  ### &lt;b&gt;
  alpha &lt;- min(1, SomeDist(temp)/SomeDist(samples[i]))
  ### &lt;/b&gt;
  if (runif(1, 0, 1) &lt; alpha) {
    samples[i + 1] &lt;- temp
  } else {
    samples[i + 1] &lt;- samples[i]
  }
}

correct_samples &lt;- samples[(n1 + 1):n2]</code></pre>
<p><img src="/post/2019-03-12-mcmc方法解析_files/figure-html/unnamed-chunk-8-1.png" width="864" /></p>
</div>
</div>
<div id="gibbs" class="section level2">
<h2>6.2 Gibbs抽样</h2>
<div id="-2" class="section level3">
<h3>问题</h3>
<p>使用Gibbs方法从二元正态分布<span class="math inline">\(N(\mu_1, \mu_2, \sigma_1^2, \sigma_2^2,\rho)\)</span>中抽样</p>
</div>
<div id="-2" class="section level3">
<h3>求解</h3>
<p>按条件有随机变量<span class="math inline">\(X_1\sim N(\mu_1,\sigma_1^2)\)</span>,<span class="math inline">\(X_2\sim N(\mu_2,\sigma_2^2)\)</span>服从正态分布。因此<span class="math inline">\(X_1|X_2\)</span>以及<span class="math inline">\(X_2|X_1\)</span>服从正态分布，且<span class="math inline">\(X_1|X_2\)</span>的期望和方差为：</p>
<p><span class="math display">\[
E[X_1|X_2=x_2]=\mu_1 + \rho\frac{\sigma_1}{\sigma_2}(x_2 - \mu_2)\\
Var[X_1|X_2=x_2]=(1 - \rho^2)\sigma_1^2
\]</span></p>
<p><span class="math inline">\(X_2|X_1\)</span>也可类比。因此条件概率密度为：</p>
<p><span class="math display">\[
f(x_1|x_2)\sim N(\mu_1 + \rho\frac{\sigma_1}{\sigma_2}(x_2 - \mu_2), (1 - \rho^2)\sigma_1^2)\\
f(x_2|x_1)\sim N(\mu_2 + \rho\frac{\sigma_2}{\sigma_2}(x_1 - \mu_1), (1 - \rho^2)\sigma_2^2)
\]</span></p>
<p>抽样过程：</p>
<pre class="r"><code>N &lt;- 5000
N.burn &lt;- 1000
X &lt;- matrix(0, N, 2)
rho &lt;- -0.6
mu1 &lt;- 2; mu2 &lt;- 10
sigma1 &lt;- 1; sigma2 &lt;- 2
s1 &lt;- sqrt(1 - rho^2)*sigma1
s2 &lt;- sqrt(1 - rho^2)*sigma2
X[1, ] &lt;- c(mu1, mu2) # 用均值点作为抽样起点
for (i in 2:N) {
  if (i %% 2 == 1) {
    # 奇数步固定x2对x1采样
    x2 &lt;- X[i - 1, 2]
    m1 &lt;- mu1 + rho*(x2 - mu2)*sigma1/sigma2
    X[i, 1] &lt;- rnorm(1, m1, s1)
    X[i, 2] &lt;- x2
  } else {
    # 偶数步固定x1对x2采样
    x1 &lt;- X[i - 1, 1]
    m2 &lt;- mu2 + rho*(x1 - mu1)*sigma2/sigma1
    X[i, 1] &lt;- x1
    X[i, 2] &lt;- rnorm(1, m2, s2)
  }
}
X.samples &lt;- X[(N.burn + 1):N,]</code></pre>
<p>采样轨迹</p>
<pre class="r"><code>X.samples.df &lt;- as.data.frame(X.samples)
names(X.samples.df) &lt;- c(&#39;X1&#39;, &#39;X2&#39;)
ggplot() +
  geom_path(data = X.samples.df[1:500,], aes(x = X1, y = X2)) +
  theme_yk_academic_light()</code></pre>
<p><img src="/post/2019-03-12-mcmc方法解析_files/figure-html/unnamed-chunk-10-1.png" width="864" /></p>
<p>由于坐标轮换采样会导致相邻两个样本之间是条件独立而非完全独立的，但不相邻的样本之间是完全独立的。因此为了保证采样的随机性，仅选取奇数下标的样本作为最终的抽样结果。</p>
<pre class="r"><code>X.samples.real &lt;- X.samples[seq(1, nrow(X.samples), by = 2),]</code></pre>
<p>均值</p>
<pre class="r"><code>colMeans(X.samples.real)</code></pre>
<pre><code>## [1]  1.964509 10.048590</code></pre>
<p>方差</p>
<pre class="r"><code>cov(X.samples.real)</code></pre>
<pre><code>##           [,1]      [,2]
## [1,]  1.006157 -1.212752
## [2,] -1.212752  3.927797</code></pre>
<p>样本分布</p>
<pre class="r"><code>X.samples.real.df &lt;- as.data.frame(X.samples.real)
names(X.samples.real.df) &lt;- c(&#39;X1&#39;, &#39;X2&#39;)
ggplot(X.samples.real.df) +
  geom_point(aes(X1, X2), alpha = .4, col = &#39;blue&#39;,size = 2) +
  theme_yk_academic_light()</code></pre>
<p><img src="/post/2019-03-12-mcmc方法解析_files/figure-html/unnamed-chunk-14-1.png" width="864" /></p>
<p>以上过程完演示了完整的Gibbs抽样，由于相邻样本间条件独立性的问题，更快的采样方式是在每次循环中采样完一个坐标以后，立即采样另一个坐标并将采样得到的两个坐标的新值合并为一个样本点，相当于从A点出发采样两次得到B和C，但是只存储C点（如下图所示）。</p>
<p><img src="/post/2019-03-12-mcmc方法解析_files/figure-html/unnamed-chunk-15-1.png" width="864" /></p>
<p><strong>改进</strong>:直接采样</p>
<pre class="r"><code>N &lt;- 5000
N.burn &lt;- 1000
X &lt;- matrix(0, N, 2)
rho &lt;- -0.6
mu1 &lt;- 2
mu2 &lt;- 10
sigma1 &lt;- 1
sigma2 &lt;- 2
s1 &lt;- sqrt(1 - rho^2)*sigma1
s2 &lt;- sqrt(1 - rho^2)*sigma2
X[1, ] &lt;- c(mu1, mu2) # 用均值点作为抽样起点

for (i in 2:N) {
  # 先固定x2对x1采样
  x2 &lt;- X[i - 1, 2]
  m1 &lt;- mu1 + rho*(x2 - mu2)*sigma1/sigma2
  X[i, 1] &lt;- rnorm(1, m1, s1)
  # 再固定x1对x2采样
  x1 &lt;- X[i, 1]
  m2 &lt;- mu2 + rho*(x1 - mu1)*sigma2/sigma1
  X[i, 2] &lt;- rnorm(1, m2, s2)
}

X.samples &lt;- X[(N.burn + 1):N,]</code></pre>
</div>
</div>
</div>
<div class="section level1">
<h1>7. 思考</h1>
<div class="section level2 build">
<h2>问题一</h2>
<p>回顾如下公式，既然对于<span class="math inline">\(\alpha(i,j)\)</span>我们将之理解为从一条马氏链过渡到另一条马氏链的跳转率（也作接受率），并且实际操作中是通过物理过程：从均匀分布中抽样这个动作来实现的。那么式中的<span class="math inline">\(q(i,j)\)</span>，作为转移矩阵中的一个点，它也是一个取值于（0,1）的概率值，它的作用形式是怎样的？ <span class="math display">\[
p(i)q(i,j)\alpha(i,j)=p(j)q(j,i)\alpha(j,i) 
\]</span></p>
<div class="section level3 build">
<h3>解答</h3>
<p>回顾实际采样过程：</p>
<ul>
<li>a 用X表示由MCMC过程产生的状态向量，<span class="math inline">\(Q_0\)</span>表示状态转移矩阵（<span class="math inline">\(D_0\)</span>表示抽样分布）。初始化<span class="math inline">\(X_0=x_0\)</span>，其中<span class="math inline">\(x_0\)</span>是从状态集（分布）中获取的随机样本。</li>
<li>b 对<span class="math inline">\(t = 0, 1, 2, \cdots,n\)</span>重复如下步骤进行采样：</li>
<li><div class="blue2">
b-1 第<span class="math inline">\(t\)</span>时刻有<span class="math inline">\(X_t=x_t\)</span>, 采样<span class="math inline">\(y~q(x|x_t)\)</span>(此时状态转移矩阵为<span class="math inline">\(Q_t=q(x|x_t)\)</span>)。
</div></li>
<li>b-2 从<span class="math inline">\(U(0,1)\)</span>中抽取一个样本点<span class="math inline">\(u\)</span></li>
<li>b-3 如果<span class="math inline">\(u&lt;\alpha(x_t, y)=min(\frac{p(j)q(j,i)}{p(i)q(i,j)},1)\)</span>则接受转移<span class="math inline">\(X_{t+1}=y\)</span></li>
<li>b-4 否则拒绝转移，<span class="math inline">\(X_{t+1}=x_t\)</span>, <span class="math inline">\(Q_{t+1} = Q_t\)</span></li>
</ul>
</div>
</div>
<div class="section level2 build">
<h2>问题二</h2>
<p>如何理解拒绝跳转这一现象？ 我们知道如果发生一次拒绝跳转，就把上一次抽样结果当做本次抽样结果放到抽样链里去。相当于该样本重复了一次，那么在最后得到的样本中是否要去除这些重复的样本（或者说只取连续游程中的第一个）？</p>
<div id="-1" class="section level3 build">
<h3>解答</h3>
<p>假设状态集合为<span class="math inline">\(S=[s_1, s_2, s_3]\)</span>,满足细致平稳条件的<span class="math inline">\(Q\prime\)</span>的矩阵结构如下式所示，可知由于乘以<span class="math inline">\(\alpha(i,j)\)</span>而丢失的概率质量全部转移到了对角线上，相当于放大了状态转移到自己的概率。而这会降低马氏链收敛到稳态的速度。 <span class="math display">\[
  Q\prime=Q\cdot A= \\
  \left\{
  \begin{matrix}
   1-\sum_{j=1}^3 p(1,j)\alpha(1,j) &amp; p(1,2)\alpha(1,2) &amp; p(1,3)\alpha(1,3) \\
   p(2,1)\alpha(2,1) &amp; 1-\sum_{j=1}^3 p(2,j)\alpha(2,j) &amp; p(2,3)\alpha(2,3) \\
   p(3,1)\alpha(3,1) &amp; p(3,2)\alpha(3,2) &amp; 1-\sum_{j=1}^3 p(3,j)\alpha(3,j)
  \end{matrix}
  \right\} \tag{1}
\]</span></p>
</div>
</div>
<div id="section" class="section level2 build">
<h2></h2>
<p>假设t-1步链上的样本为<span class="math inline">\(s^{(t-1)}=s_1\)</span>，同时t步已抽取样本<span class="math inline">\(s^t=s_2\)</span>,则此时<span class="math inline">\(Q\prime|s^t=s_2\)</span>具有如下形式，由下式可知这就是跳转的真实过程。 <span class="math display">\[
  Q\prime|(s^{(t-1)} = s_1,s^t=s_2)=(Q\cdot A)|(s^{(t-1)} = s_1,s^t=s_2)\\
  =
  \left\{
  \begin{matrix}
   (1-\sum_{j=1}^3 p(1,j)\alpha(1,j))|_t &amp; (p(1,2)\alpha(1,2))|_t &amp; (p(1,3)\alpha(1,3))|_t \\
   \dots &amp; \dots &amp; \dots \\
   \dots &amp; \dots &amp; \dots
  \end{matrix}
  \right\} \\ 
  =
  \left\{
  \begin{matrix}
   1-p(1,2)\alpha(1,2) &amp; p(1,2)\alpha(1,2) &amp; 0 \\
   \dots &amp; \dots &amp; \dots \\
   \dots &amp; \dots &amp; \dots
  \end{matrix}
  \right\}
\]</span></p>
</div>
<div class="section level2 build">
<h2>问题三</h2>
<p>如何确定Burn-In过程的长度，即：该舍弃多少次抽样？</p>
<div id="-2" class="section level3 build">
<h3>解答</h3>
<p>视问题复杂度，总体上多多益善。</p>
</div>
</div>
</div>
<div class="section level1">
<h1>8.参考资料</h1>
<ul>
<li>[1] 靳志辉《LDA数学八卦》</li>
<li>[2] 韦来生《贝叶斯统计》</li>
<li>[3] 浙江大学出版社《概率论与数理统计》</li>
</ul>
</div>
